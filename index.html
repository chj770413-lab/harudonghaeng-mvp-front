<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>í•˜ë£¨ë™í–‰ ìŒì„±</title>

  <style>
    body {
      margin: 0;
      height: 100vh;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      font-family: system-ui, -apple-system, BlinkMacSystemFont;
      background: #ffffff;
    }
    h1 {
      font-size: 28px;
      margin-bottom: 40px;
    }
    button {
      width: 140px;
      height: 140px;
      border-radius: 50%;
      font-size: 48px;
      border: none;
      background: #2f80ed;
      color: white;
    }
    button.recording {
      background: #eb5757;
    }
    p {
      margin-top: 30px;
      font-size: 14px;
      color: #777;
    }
  </style>
</head>

<body>

  <h1>ë§ì”€í•´ ì£¼ì„¸ìš”.</h1>

  <button id="micBtn">ğŸ¤</button>

  <p>ì²œì²œíˆ ë§ì”€í•˜ì…”ë„ ê´œì°®ì•„ìš”.</p>

 <script>
   function speak(text) {
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.lang = "ko-KR";
  utterance.rate = 0.9;   // ì‹œë‹ˆì–´ì—ê²Œ í¸í•œ ì†ë„
  utterance.pitch = 1.0;
  speechSynthesis.cancel(); // ì´ì „ ìŒì„± ì¤‘ë‹¨
  speechSynthesis.speak(utterance);
}

  const micBtn = document.getElementById("micBtn");

  const SpeechRecognition =
    window.SpeechRecognition || window.webkitSpeechRecognition;

  if (!SpeechRecognition) {
    alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í¬ë¡¬ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.");
  }

  const recognition = new SpeechRecognition();
  recognition.lang = "ko-KR";
  recognition.interimResults = false;
  recognition.maxAlternatives = 1;
  recognition.continuous = false;

  let isListening = false;

  // âœ… ë²„íŠ¼ì€ startë§Œ ë‹´ë‹¹ (stopì€ ì´ë²¤íŠ¸ì—ì„œë§Œ)
  micBtn.onclick = () => {
    if (isListening) return;
    recognition.start();
  };

  // ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘
  recognition.onstart = () => {
    isListening = true;
    micBtn.classList.add("recording");
    console.log("ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘");
  };

  recognition.onresult = async (event) => {
  const text = event.results[0][0].transcript;
  console.log("ì¸ì‹ëœ ë¬¸ì¥:", text);

  try {
    const res = await fetch("/api/chat", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({ message: text }), // âœ… ì—¬ê¸°!
    });

    const data = await res.json();
    speak(data.reply);
  } catch (e) {
    alert("ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.");
  }
};

  // âŒ ì˜¤ë¥˜ ì²˜ë¦¬
  recognition.onerror = (event) => {
    alert("ìŒì„± ì¸ì‹ ì˜¤ë¥˜: " + event.error);
    isListening = false;
    micBtn.classList.remove("recording");
  };

  // ğŸ›‘ ì¸ì‹ ì¢…ë£Œ
  recognition.onend = () => {
    isListening = false;
    micBtn.classList.remove("recording");
    console.log("ğŸ¤ ìŒì„± ì¸ì‹ ì¢…ë£Œ");
  };
</script>

</body>
</html>
